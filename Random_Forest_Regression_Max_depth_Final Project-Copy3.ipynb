{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports.\n",
    "import numpy as np                          # for array operations\n",
    "import pandas as pd                          # for working with DataFrames\n",
    "import matplotlib.pyplot as plt        # for data visualization\n",
    "%matplotlib inline                               \n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import OneHotEncoder                # transform categorical features into numerical dummy features (training)\n",
    "from sklearn.model_selection import train_test_split              # for splitting the data\n",
    "from sklearn.metrics import mean_squared_error                   # for calculating average\n",
    "from sklearn.ensemble import RandomForestRegressor         # for building the model\n",
    "from sklearn.metrics import r2_score                                        # evaluate performance of a linear regression model\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5355cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "file_path = (\"causes_of_death.csv\")\n",
    "death_df = pd.read_csv(file_path)\n",
    "death_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "death_cat = death_df.dtypes[death_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "death_df[death_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16929afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdab8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ad98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique value counts to see if binning is required\n",
    "death_df['Cause Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff26706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique value counts to see if binning is required\n",
    "death_df['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not useful\n",
    "death_df =  death_df.drop('Cause Name 113', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21deaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df_encoded = pd.get_dummies(death_df, columns=[\"Cause Name\", \"State\"])\n",
    "death_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features data set.\n",
    "X = death_df_encoded.copy()\n",
    "#X = X.drop([\"Death Rate\",\"Deaths\", \"Cause Name_All causes\", \"Cause Name_Cancer\", \"Cause Name_Heart disease\"], axis=1)\n",
    "X = X.drop([\"Death Rate\",\"Deaths\", \"Cause Name_All causes\"], axis=1)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target data set.\n",
    "y = death_df[\"Death Rate\"].ravel()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1793021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing set (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Random Forest Regression model with 128 decision trees\n",
    "model = RandomForestRegressor(n_estimators =128, max_features = 'sqrt', max_depth = 7, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Random Forest Regression model to the data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81387112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the target values of the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb9045f",
   "metadata": {},
   "source": [
    "To calculate the loss between the actual target values in the testing set and the values predicted by the model, a cost function called the Root Mean Square Error (RMSE) is used.\n",
    "\n",
    "The RMSE  indicates how close the actual data points are to the model’s predicted values. When RMSE value is low it indicates a better fit and is a good measure for determining the accuracy of the model’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE (Root Mean Square Error)\n",
    "rmse = float(format(np.sqrt(mean_squared_error(y_test, y_pred)),'.3f'))\n",
    "print(\"\\nRMSE:\\n\",rmse)\n",
    "\n",
    "# RMSE for training....verifying if data leakage was occuring\n",
    "#rmse = float(format(np.sqrt(mean_squared_error(y_train, model.predict(X_train))),'.3f'))\n",
    "#print(\"\\nRMSE:\\n\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfde398",
   "metadata": {},
   "source": [
    "R² score indicates how will our model is fitte to the data by comparing it to the average line of the dependent variable (y or target). A score closer to 1, implies our model preformed well verses if score is further from 1, implying our model did not perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score.....indicates that 20% of the variancce in the causes of death can be explained??? \n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6850a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame({'feature': X.columns, 'feature_importance':model.feature_importances_})\n",
    "df_feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.sort_values('feature_importance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
